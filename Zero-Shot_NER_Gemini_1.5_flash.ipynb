{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK1o4aIpzMYJ"
      },
      "source": [
        "Name: Biruk Kiros Meles\n",
        "\n",
        "\n",
        "Single Run zero shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us02UDm6zJ30"
      },
      "source": [
        "The conll2003_data's English data was taken from the Reuters Corpus. This corpus consists of Reuters news stories between August 1996 and August 1997."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvnYeVVNcCql"
      },
      "source": [
        "LLM: Gemini 1.5 flash Free tier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SaxvxGoPNiM"
      },
      "outputs": [],
      "source": [
        "# Initial setup - import all required libraries\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "import numpy as np\n",
        "import openai  # or your chosen LLM client\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "# Create a directory to store the data\n",
        "data_dir = \"/content/conll2003_data\"  # Colab paths start with /content/\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Download the dataset\n",
        "dataset_url = \"https://data.deepai.org/conll2003.zip\"\n",
        "zip_path = os.path.join(data_dir, \"conll2003.zip\")\n",
        "urllib.request.urlretrieve(dataset_url, zip_path)\n",
        "\n",
        "# Extract the files\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(data_dir)\n",
        "\n",
        "print(f\"Dataset downloaded to: {data_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH8uuccsUPfI"
      },
      "source": [
        "check the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcsMFzseURAa",
        "outputId": "706978b3-aad4-4f67-998f-deaeda16a762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 5716\n",
            "-rw-r--r-- 1 root root  982975 Jun 14 21:35 conll2003.zip\n",
            "-rw-r--r-- 1 root root     153 Jun 14 21:35 metadata\n",
            "-rw-r--r-- 1 root root  748095 Jun 14 21:35 test.txt\n",
            "-rw-r--r-- 1 root root 3283420 Jun 14 21:35 train.txt\n",
            "-rw-r--r-- 1 root root  827443 Jun 14 21:35 valid.txt\n"
          ]
        }
      ],
      "source": [
        "# Check what files we have\n",
        "!ls -l \"/content/conll2003_data\"\n",
        "\n",
        "# Expected files:\n",
        "# - test.txt\n",
        "# - train.txt\n",
        "# - valid.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CoF8ZH1UYt0"
      },
      "source": [
        "see the sentecnes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhlX8KWUaNy",
        "outputId": "499f676c-a417-4376-fb0d-e7e83553c0f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First 5 sentences from /content/conll2003_data/train.txt:\n",
            "1. -DOCSTART-\n",
            "2. EU rejects German call to boycott British lamb .\n",
            "3. Peter Blackburn\n",
            "4. BRUSSELS 1996-08-22\n",
            "5. The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
            "\n",
            "First 3 sentences from /content/conll2003_data/valid.txt:\n",
            "1. -DOCSTART-\n",
            "2. CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY .\n",
            "3. LONDON 1996-08-30\n",
            "\n",
            "First 3 sentences from /content/conll2003_data/test.txt:\n",
            "1. -DOCSTART-\n",
            "2. SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "3. Nadim Ladki\n"
          ]
        }
      ],
      "source": [
        "def view_sentences(file_path, num_samples=5):\n",
        "    \"\"\"View sample sentences from a file\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        current_sentence = []\n",
        "        samples_shown = 0\n",
        "\n",
        "        print(f\"\\nFirst {num_samples} sentences from {file_path}:\")\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    print(f\"{samples_shown+1}. {' '.join(current_sentence)}\")\n",
        "                    current_sentence = []\n",
        "                    samples_shown += 1\n",
        "                    if samples_shown >= num_samples:\n",
        "                        break\n",
        "                continue\n",
        "            token = line.split()[0]  # First item is the token\n",
        "            current_sentence.append(token)\n",
        "\n",
        "# View training set sentences\n",
        "view_sentences(\"/content/conll2003_data/train.txt\")\n",
        "\n",
        "# View validation set sentences\n",
        "view_sentences(\"/content/conll2003_data/valid.txt\", 3)\n",
        "\n",
        "# View test set sentences\n",
        "view_sentences(\"/content/conll2003_data/test.txt\", 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZZ8ZHXuVhTE"
      },
      "source": [
        "#Display the senteces and their tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVB3dWy6VkQ0",
        "outputId": "33278849-0717-49c2-ec9b-13a72818ad6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tagged samples from /content/conll2003_data/train.txt:\n",
            "\n",
            "Sentence 1:\n",
            "Text: EU rejects German call to boycott British lamb .\n",
            "Tokens: ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "POS Tags: ['NNP', 'VBZ', 'JJ', 'NN', 'TO', 'VB', 'JJ', 'NN', '.']\n",
            "NER Tags: ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
            "\n",
            "Sentence 2:\n",
            "Text: Peter Blackburn\n",
            "Tokens: ['Peter', 'Blackburn']\n",
            "POS Tags: ['NNP', 'NNP']\n",
            "NER Tags: ['B-PER', 'I-PER']\n",
            "\n",
            "Sentence 3:\n",
            "Text: BRUSSELS 1996-08-22\n",
            "Tokens: ['BRUSSELS', '1996-08-22']\n",
            "POS Tags: ['NNP', 'CD']\n",
            "NER Tags: ['B-LOC', 'O']\n",
            "\n",
            "Sentence 4:\n",
            "Text: The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep .\n",
            "Tokens: ['The', 'European', 'Commission', 'said', 'on', 'Thursday', 'it', 'disagreed', 'with', 'German', 'advice', 'to', 'consumers', 'to', 'shun', 'British', 'lamb', 'until', 'scientists', 'determine', 'whether', 'mad', 'cow', 'disease', 'can', 'be', 'transmitted', 'to', 'sheep', '.']\n",
            "POS Tags: ['DT', 'NNP', 'NNP', 'VBD', 'IN', 'NNP', 'PRP', 'VBD', 'IN', 'JJ', 'NN', 'TO', 'NNS', 'TO', 'VB', 'JJ', 'NN', 'IN', 'NNS', 'VBP', 'IN', 'JJ', 'NN', 'NN', 'MD', 'VB', 'VBN', 'TO', 'NN', '.']\n",
            "NER Tags: ['O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "\n",
            "Sentence 5:\n",
            "Text: Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .\n",
            "Tokens: ['Germany', \"'s\", 'representative', 'to', 'the', 'European', 'Union', \"'s\", 'veterinary', 'committee', 'Werner', 'Zwingmann', 'said', 'on', 'Wednesday', 'consumers', 'should', 'buy', 'sheepmeat', 'from', 'countries', 'other', 'than', 'Britain', 'until', 'the', 'scientific', 'advice', 'was', 'clearer', '.']\n",
            "POS Tags: ['NNP', 'POS', 'NN', 'TO', 'DT', 'NNP', 'NNP', 'POS', 'JJ', 'NN', 'NNP', 'NNP', 'VBD', 'IN', 'NNP', 'NNS', 'MD', 'VB', 'NN', 'IN', 'NNS', 'JJ', 'IN', 'NNP', 'IN', 'DT', 'JJ', 'NN', 'VBD', 'JJR', '.']\n",
            "NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "def view_tagged_sentences(file_path, num_samples=2):\n",
        "    \"\"\"View sentences with their NER and POS tags, skipping the first line of the file\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        next(f)  # Skip the first line\n",
        "\n",
        "        current_sentence = []\n",
        "        current_pos_tags = []\n",
        "        current_ner_tags = []\n",
        "        samples_shown = 0\n",
        "\n",
        "        print(f\"\\nTagged samples from {file_path}:\")\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    print(f\"\\nSentence {samples_shown+1}:\")\n",
        "                    print(\"Text:\", ' '.join(current_sentence))\n",
        "                    print(\"Tokens:\", current_sentence)\n",
        "                    print(\"POS Tags:\", current_pos_tags)\n",
        "                    print(\"NER Tags:\", current_ner_tags)\n",
        "\n",
        "                    current_sentence = []\n",
        "                    current_pos_tags = []\n",
        "                    current_ner_tags = []\n",
        "                    samples_shown += 1\n",
        "                    if samples_shown >= num_samples:\n",
        "                        break\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 4:\n",
        "                current_sentence.append(parts[0])       # Token\n",
        "                current_pos_tags.append(parts[1])       # POS tag\n",
        "                current_ner_tags.append(parts[-1])      # NER tag (last element)\n",
        "view_tagged_sentences(\"/content/conll2003_data/train.txt\", 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNmz1dpLVtFG"
      },
      "source": [
        "Analyze TAG distribution\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "3_SdMNnfVwn5",
        "outputId": "0b26314c-c1b9-4b40-c3c0-cdefdc5b0413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tag distribution in /content/conll2003_data/train.txt:\n",
            "O: 170523\n",
            "B-LOC: 7140\n",
            "B-PER: 6600\n",
            "B-ORG: 6321\n",
            "I-PER: 4528\n",
            "I-ORG: 3704\n",
            "B-MISC: 3438\n",
            "I-LOC: 1157\n",
            "I-MISC: 1155\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def analyze_tags(file_path):\n",
        "    tag_counter = Counter()\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        next(f)\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:  # Skip empty lines\n",
        "                tag = line.split()[-1]  # Last element is NER tag\n",
        "                tag_counter[tag] += 1\n",
        "\n",
        "    print(f\"\\nTag distribution in {file_path}:\")\n",
        "    for tag, count in tag_counter.most_common():\n",
        "        print(f\"{tag}: {count}\")\n",
        "\n",
        "    # Plot the distribution\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(tag_counter.keys(), tag_counter.values())##Important! - Log distribution\n",
        "    plt.title(f\"NER Tag Distribution in {file_path.split('/')[-1]}\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Analyze training set tags\n",
        "analyze_tags(\"/content/conll2003_data/train.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMlAbQ4CWQdC"
      },
      "source": [
        "#Proper data split\n",
        "\n",
        "\n",
        "Incase there will be a need for finetuning a local model too.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2EVgeIwWTmK",
        "outputId": "b7f260e0-c84d-4774-f250-f59bc92effb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 299 dev (prompt tuning) sentences\n",
            "Loaded 3683 test sentences for evaluation\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_for_zero_shot_ner_with_pos(data_dir=\"/content/conll2003_data\",\n",
        "                                   val_size=0.05,\n",
        "                                   random_state=42):\n",
        "    \"\"\"\n",
        "    Load dataset for zero-shot NER with POS tags.\n",
        "    Only returns a small dev set for prompt testing and a test set for evaluation.\n",
        "\n",
        "    Returns:\n",
        "        dev_data: list of dicts with tokens, pos_tags, tags\n",
        "        test_data: list of dicts with tokens, pos_tags, tags\n",
        "    \"\"\"\n",
        "    def load_conll_file(file_path):\n",
        "        sentences = []\n",
        "        current_sentence = []\n",
        "        current_pos_tags = []\n",
        "        current_tags = []\n",
        "\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            next(f)  # skip header\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    if current_sentence:\n",
        "                        sentences.append({\n",
        "                            'tokens': current_sentence,\n",
        "                            'pos_tags': current_pos_tags,\n",
        "                            'tags': current_tags\n",
        "                        })\n",
        "                        current_sentence = []\n",
        "                        current_pos_tags = []\n",
        "                        current_tags = []\n",
        "                    continue\n",
        "                parts = line.split()\n",
        "                current_sentence.append(parts[0])      # token\n",
        "                current_pos_tags.append(parts[1])      # pos tag (2nd column)\n",
        "                current_tags.append(parts[-1])         # ner tag (last column)\n",
        "        return sentences\n",
        "\n",
        "    # Load full training and test data\n",
        "    full_train_data = load_conll_file(f\"{data_dir}/train.txt\")\n",
        "    test_data = load_conll_file(f\"{data_dir}/test.txt\")\n",
        "\n",
        "    # Split training data to get dev set for prompt tuning\n",
        "    if val_size > 0:\n",
        "        dev_data, _ = train_test_split(\n",
        "            full_train_data,\n",
        "            test_size=1 - val_size,\n",
        "            random_state=random_state\n",
        "        )\n",
        "        print(f\"Loaded {len(dev_data)} dev (prompt tuning) sentences\")\n",
        "    else:\n",
        "        dev_data = []\n",
        "\n",
        "    print(f\"Loaded {len(test_data)} test sentences for evaluation\")\n",
        "\n",
        "    return dev_data, test_data\n",
        "\n",
        "# Usage example\n",
        "dev_data, test_data = load_for_zero_shot_ner_with_pos(val_size=0.02)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0opZX8uOtGZ",
        "outputId": "b9f79e9f-0735-4da2-b1df-eb895f120e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=f8c85fe5be64308671d9fc0d891d55c7367ed2854076f612c35c9ad739021b80\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuX4p7xON9RA"
      },
      "source": [
        "#Lets see the structure of our dev_data and test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ih0evFnWUkb",
        "outputId": "7044a0d2-16f5-4a85-b751-fcf2ef618f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📄 Prompt Tuning (Dev) Data (3 samples shown):\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 Sentence 1:\n",
            "Text: The Russians , working for the Aerostan firm in the Russian republic of Tatarstan , were taken hostage after a Taleban MiG-19 fighter forced their cargo plane to land in August 1995 .\n",
            "Tokens: ['The', 'Russians', ',', 'working', 'for', 'the', 'Aerostan', 'firm', 'in', 'the', 'Russian', 'republic', 'of', 'Tatarstan', ',', 'were', 'taken', 'hostage', 'after', 'a', 'Taleban', 'MiG-19', 'fighter', 'forced', 'their', 'cargo', 'plane', 'to', 'land', 'in', 'August', '1995', '.']\n",
            "POS Tags: ['DT', 'NNPS', ',', 'VBG', 'IN', 'DT', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', 'NNP', ',', 'VBD', 'VBN', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'NN', 'VBD', 'PRP$', 'NN', 'NN', 'TO', 'VB', 'IN', 'NNP', 'CD', '.']\n",
            "NER Tags: ['O', 'B-MISC', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Entities:\n",
            "  - Russians [MISC]\n",
            "  - Aerostan [ORG]\n",
            "  - Russian [MISC]\n",
            "  - Tatarstan [LOC]\n",
            "  - Taleban [MISC]\n",
            "  - MiG-19 [MISC]\n",
            "\n",
            "🔹 Sentence 2:\n",
            "Text: Yeltsin on holiday from Monday - Interfax .\n",
            "Tokens: ['Yeltsin', 'on', 'holiday', 'from', 'Monday', '-', 'Interfax', '.']\n",
            "POS Tags: ['NN', 'IN', 'NN', 'IN', 'NNP', ':', 'NNP', '.']\n",
            "NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O']\n",
            "Entities:\n",
            "  - Yeltsin [PER]\n",
            "  - Interfax [ORG]\n",
            "\n",
            "🔹 Sentence 3:\n",
            "Text: Zadar police said in a statement they had launched an investigation and were doing their best to find the perpetrators .\n",
            "Tokens: ['Zadar', 'police', 'said', 'in', 'a', 'statement', 'they', 'had', 'launched', 'an', 'investigation', 'and', 'were', 'doing', 'their', 'best', 'to', 'find', 'the', 'perpetrators', '.']\n",
            "POS Tags: ['NN', 'NN', 'VBD', 'IN', 'DT', 'NN', 'PRP', 'VBD', 'VBN', 'DT', 'NN', 'CC', 'VBD', 'VBG', 'PRP$', 'JJS', 'TO', 'VB', 'DT', 'NNS', '.']\n",
            "NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Entities:\n",
            "  - Zadar [LOC]\n",
            "\n",
            "📄 Evaluation (Test) Data (3 samples shown):\n",
            "--------------------------------------------------\n",
            "\n",
            "🔹 Sentence 1:\n",
            "Text: SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "Tokens: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "POS Tags: ['NN', ':', 'NNP', 'VB', 'NNP', 'NNP', ',', 'NNP', 'IN', 'DT', 'NN', '.']\n",
            "NER Tags: ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
            "Entities:\n",
            "  - JAPAN [LOC]\n",
            "  - CHINA [PER]\n",
            "\n",
            "🔹 Sentence 2:\n",
            "Text: Nadim Ladki\n",
            "Tokens: ['Nadim', 'Ladki']\n",
            "POS Tags: ['NNP', 'NNP']\n",
            "NER Tags: ['B-PER', 'I-PER']\n",
            "Entities:\n",
            "  - Nadim Ladki [PER]\n",
            "\n",
            "🔹 Sentence 3:\n",
            "Text: AL-AIN , United Arab Emirates 1996-12-06\n",
            "Tokens: ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "POS Tags: ['NNP', ',', 'NNP', 'NNP', 'NNPS', 'CD']\n",
            "NER Tags: ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
            "Entities:\n",
            "  - AL-AIN [LOC]\n",
            "  - United Arab Emirates [LOC]\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics.sequence_labeling import get_entities\n",
        "\n",
        "def display_ner_samples_with_pos(data, num_samples=3, title=\"Sample Sentences\"):\n",
        "    print(f\"\\n📄 {title} ({num_samples} samples shown):\\n\" + \"-\" * 50)\n",
        "\n",
        "    for i, sample in enumerate(data[:num_samples]):\n",
        "        tokens = sample['tokens']\n",
        "        pos_tags = sample.get('pos_tags', ['_'] * len(tokens))  # fallback if missing\n",
        "        tags = sample['tags']\n",
        "        sentence = \" \".join(tokens)\n",
        "        entities = get_entities(tags)  # list of (entity_type, start, end)\n",
        "\n",
        "        print(f\"\\n🔹 Sentence {i+1}:\")\n",
        "        print(\"Text:\", sentence)\n",
        "        print(\"Tokens:\", tokens)\n",
        "        print(\"POS Tags:\", pos_tags)\n",
        "        print(\"NER Tags:\", tags)\n",
        "\n",
        "        if entities:\n",
        "            print(\"Entities:\")\n",
        "            for ent_type, start, end in entities:\n",
        "                entity_text = \" \".join(tokens[start:end+1])\n",
        "                print(f\"  - {entity_text} [{ent_type}]\")\n",
        "        else:\n",
        "            print(\"Entities: None\")\n",
        "\n",
        "# Run display\n",
        "display_ner_samples_with_pos(dev_data, num_samples=3, title=\"Prompt Tuning (Dev) Data\")\n",
        "display_ner_samples_with_pos(test_data, num_samples=3, title=\"Evaluation (Test) Data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N72mUtt0ZksC"
      },
      "source": [
        "#Our NER processing class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lj7xJ4TGZmUJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ANSI color codes for error highlighting\n",
        "class Colors:\n",
        "    RED = '\\033[91m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    BLUE = '\\033[94m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "\n",
        "# Load English language model for syntactic parsing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class ConllNERProcessor:\n",
        "\n",
        "    def __init__(self, api_key='your_api_key'):\n",
        "        self.api_key = api_key\n",
        "        self.endpoint = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\"\n",
        "        self.headers = {'Content-Type': 'application/json'}\n",
        "        self.request_count = 0\n",
        "        self.last_request_time = datetime.now()\n",
        "        self.entity_types = ['PER', 'ORG', 'LOC', 'MISC']\n",
        "        self.rate_limit = {\n",
        "            'requests_per_minute': 60,\n",
        "            'requests_per_batch': 15,\n",
        "            'batch_interval': 60  # seconds\n",
        "        }\n",
        "        # Enhanced backoff parameters\n",
        "        self.backoff_factor = 60\n",
        "        self.max_backoff = 320\n",
        "\n",
        "    def _rate_limit(self):\n",
        "        \"\"\"Enforce rate limiting with adaptive backoff\"\"\"\n",
        "        now = datetime.now()\n",
        "        elapsed = (now - self.last_request_time).total_seconds()\n",
        "\n",
        "        # Reset counter if more than batch interval has passed\n",
        "        if elapsed > self.rate_limit['batch_interval']:\n",
        "            self.request_count = 0\n",
        "            self.last_request_time = now\n",
        "            return\n",
        "\n",
        "        # Check if we need to wait\n",
        "        if self.request_count >= self.rate_limit['requests_per_batch']:\n",
        "            wait_time = self.rate_limit['batch_interval'] - elapsed\n",
        "            print(f\"{Colors.YELLOW}Rate limit: Waiting {wait_time:.1f} seconds...{Colors.ENDC}\")\n",
        "            time.sleep(wait_time)\n",
        "            self.request_count = 0\n",
        "            self.last_request_time = datetime.now()\n",
        "\n",
        "    def generate(self, prompt, temperature=0, max_retries=5):\n",
        "        \"\"\"Send prompt with enhanced rate limiting and retry logic\"\"\"\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self._rate_limit()\n",
        "\n",
        "                params = {'key': self.api_key}\n",
        "                payload = {\n",
        "                    \"contents\": [{\n",
        "                        \"parts\": [{\n",
        "                            \"text\": prompt\n",
        "                        }]\n",
        "                    }],\n",
        "                    \"generationConfig\": {\n",
        "                        \"responseMimeType\": \"application/json\",\n",
        "                        \"temperature\": temperature\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                response = requests.post(\n",
        "                    self.endpoint,\n",
        "                    params=params,\n",
        "                    headers=self.headers,\n",
        "                    json=payload,\n",
        "                    timeout=120  # Increased timeout\n",
        "                )\n",
        "\n",
        "                response.raise_for_status()\n",
        "                return response.json()\n",
        "\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                if e.response.status_code == 429:\n",
        "                    backoff = min(self.max_backoff, self.backoff_factor ** (attempt + 1))\n",
        "                    print(f\"{Colors.RED}Rate limited (429). Waiting {backoff}s...{Colors.ENDC}\")\n",
        "                    time.sleep(backoff)\n",
        "                    continue\n",
        "                print(f\"{Colors.RED}HTTP Error: {e}{Colors.ENDC}\")\n",
        "                return None\n",
        "            except requests.exceptions.Timeout:\n",
        "                print(f\"{Colors.RED}Request timeout. Retrying...{Colors.ENDC}\")\n",
        "                time.sleep(3)\n",
        "            except Exception as e:\n",
        "                print(f\"{Colors.RED}Attempt {attempt + 1} failed: {str(e)}{Colors.ENDC}\")\n",
        "                time.sleep(1)\n",
        "\n",
        "        print(f\"{Colors.RED}Failed after {max_retries} attempts{Colors.ENDC}\")\n",
        "        return None\n",
        "\n",
        "    def prepare_conll_example(self, sentence_data):\n",
        "        \"\"\"Convert CoNLL format to text with entity markers\"\"\"\n",
        "        tokens = sentence_data['tokens']\n",
        "        tags = sentence_data['tags']\n",
        "\n",
        "        # Convert BIO tags to entity spans\n",
        "        entities = []\n",
        "        current_entity = None\n",
        "        start_idx = 0\n",
        "\n",
        "        for i, tag in enumerate(tags):\n",
        "            if tag.startswith('B-'):\n",
        "                if current_entity is not None:\n",
        "                    entities.append((start_idx, i-1, current_entity))\n",
        "                current_entity = tag[2:]\n",
        "                start_idx = i\n",
        "            elif tag.startswith('I-'):\n",
        "                if current_entity is None or tag[2:] != current_entity:\n",
        "                    # Invalid tag sequence, treat as O\n",
        "                    if current_entity is not None:\n",
        "                        entities.append((start_idx, i-1, current_entity))\n",
        "                    current_entity = None\n",
        "            else:  # O\n",
        "                if current_entity is not None:\n",
        "                    entities.append((start_idx, i-1, current_entity))\n",
        "                    current_entity = None\n",
        "\n",
        "        if current_entity is not None:\n",
        "            entities.append((start_idx, len(tokens)-1, current_entity))\n",
        "\n",
        "        return tokens, entities\n",
        "\n",
        "    def evaluate_predictions(self, gold_data, pred_entities):\n",
        "        \"\"\"Calculate precision, recall, and F1 with detailed error analysis\"\"\"\n",
        "        true_pos = 0\n",
        "        false_pos = 0\n",
        "        false_neg = 0\n",
        "        error_details = []\n",
        "\n",
        "        for i, (gold, pred) in enumerate(zip(gold_data, pred_entities)):\n",
        "            gold_tokens, gold_ents = gold\n",
        "            gold_set = set((start, end, type) for start, end, type in gold_ents)\n",
        "            pred_set = set((start, end, type) for start, end, type in pred)\n",
        "\n",
        "            # Calculate metrics\n",
        "            tp = len(gold_set & pred_set)\n",
        "            fp = len(pred_set - gold_set)\n",
        "            fn = len(gold_set - pred_set)\n",
        "\n",
        "            true_pos += tp\n",
        "            false_pos += fp\n",
        "            false_neg += fn\n",
        "\n",
        "            # Store error details for visualization\n",
        "            if fp > 0 or fn > 0:\n",
        "                error_details.append({\n",
        "                    'index': i,\n",
        "                    'tokens': gold_tokens,\n",
        "                    'gold_entities': gold_ents,\n",
        "                    'pred_entities': pred,\n",
        "                    'tp': tp,\n",
        "                    'fp': fp,\n",
        "                    'fn': fn\n",
        "                })\n",
        "\n",
        "        precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
        "        recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'true_pos': true_pos,\n",
        "            'false_pos': false_pos,\n",
        "            'false_neg': false_neg,\n",
        "            'error_details': error_details\n",
        "        }\n",
        "\n",
        "    def visualize_errors(self, tokens, gold_ents, pred_ents):\n",
        "        \"\"\"Visualize errors with color highlighting\"\"\"\n",
        "        # Create token-level entity markers\n",
        "        gold_markers = [None] * len(tokens)\n",
        "        pred_markers = [None] * len(tokens)\n",
        "\n",
        "        # Mark gold entities\n",
        "        for start, end, etype in gold_ents:\n",
        "            for i in range(start, end + 1):\n",
        "                if i < len(tokens):\n",
        "                    gold_markers[i] = etype\n",
        "\n",
        "        # Mark predicted entities\n",
        "        for start, end, etype in pred_ents:\n",
        "            for i in range(start, end + 1):\n",
        "                if i < len(tokens):\n",
        "                    pred_markers[i] = etype\n",
        "\n",
        "        # Generate colored output\n",
        "        output = []\n",
        "        i = 0\n",
        "        while i < len(tokens):\n",
        "            # Check for matching entities\n",
        "            if gold_markers[i] == pred_markers[i] and gold_markers[i] is not None:\n",
        "                # Correct entity\n",
        "                start = i\n",
        "                entity_type = gold_markers[i]\n",
        "                while i < len(tokens) and gold_markers[i] == entity_type:\n",
        "                    i += 1\n",
        "                entity_text = \" \".join(tokens[start:i])\n",
        "                output.append(f\"{Colors.GREEN}[{entity_text}:{entity_type}]{Colors.ENDC}\")\n",
        "                continue\n",
        "\n",
        "            # Handle errors\n",
        "            if gold_markers[i] is not None:\n",
        "                # False negative (gold entity not predicted)\n",
        "                start = i\n",
        "                entity_type = gold_markers[i]\n",
        "                while i < len(tokens) and gold_markers[i] == entity_type:\n",
        "                    i += 1\n",
        "                entity_text = \" \".join(tokens[start:i])\n",
        "                output.append(f\"{Colors.RED}[{entity_text}:{entity_type}]{Colors.ENDC}\")\n",
        "                continue\n",
        "\n",
        "            if pred_markers[i] is not None:\n",
        "                # False positive (predicted entity not in gold)\n",
        "                start = i\n",
        "                entity_type = pred_markers[i]\n",
        "                while i < len(tokens) and pred_markers[i] == entity_type:\n",
        "                    i += 1\n",
        "                entity_text = \" \".join(tokens[start:i])\n",
        "                output.append(f\"{Colors.BLUE}[{entity_text}:{entity_type}]{Colors.ENDC}\")\n",
        "                continue\n",
        "\n",
        "            # No entity\n",
        "            output.append(tokens[i])\n",
        "            i += 1\n",
        "\n",
        "        return \" \".join(output)\n",
        "\n",
        "    def _parse_response(self, response):\n",
        "        \"\"\"More robust response parsing\"\"\"\n",
        "        try:\n",
        "            content = response['candidates'][0]['content']['parts'][0]['text']\n",
        "\n",
        "            # Clean response - sometimes Gemini adds extra text\n",
        "            json_start = content.find('[')\n",
        "            json_end = content.rfind(']') + 1\n",
        "\n",
        "            if json_start == -1 or json_end == 0:\n",
        "                return []\n",
        "\n",
        "            entities = json.loads(content[json_start:json_end])\n",
        "\n",
        "            # Validate entities format\n",
        "            valid_entities = []\n",
        "            for entity in entities:\n",
        "                if isinstance(entity, list) and len(entity) == 2:\n",
        "                    if isinstance(entity[0], str) and isinstance(entity[1], str):\n",
        "                        valid_entities.append(entity)\n",
        "            return valid_entities\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"{Colors.RED}Error parsing response: {e}{Colors.ENDC}\")\n",
        "            return []\n",
        "\n",
        "    def _find_token_spans(self, sentence_tokens, entity_tokens):\n",
        "        \"\"\"Find all possible spans matching entity tokens in sentence\"\"\"\n",
        "        matches = []\n",
        "        sentence_len = len(sentence_tokens)\n",
        "        entity_len = len(entity_tokens)\n",
        "\n",
        "        for i in range(sentence_len - entity_len + 1):\n",
        "            match = True\n",
        "            for j in range(entity_len):\n",
        "                if sentence_tokens[i+j].lower() != entity_tokens[j].lower():\n",
        "                    match = False\n",
        "                    break\n",
        "            if match:\n",
        "                matches.append((i, i+entity_len-1))\n",
        "\n",
        "        return matches\n",
        "\n",
        "    def evaluate_method(self, method_name, dataset, sample_size=None, max_errors=10):\n",
        "        \"\"\"Evaluate a method on a dataset with progress tracking and error visualization\"\"\"\n",
        "        if sample_size:\n",
        "            dataset = dataset[:sample_size]\n",
        "\n",
        "        results = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Prepare gold data with tokens\n",
        "        gold_data = []\n",
        "        for sample in dataset:\n",
        "            tokens, entities = self.prepare_conll_example(sample)\n",
        "            gold_data.append((tokens, entities))\n",
        "\n",
        "        for i, sample in enumerate(dataset):\n",
        "            print(f\"\\rProcessing {i+1}/{len(dataset)}...\", end=\"\", flush=True)\n",
        "\n",
        "            if method_name == 'decomposed_qa':\n",
        "                pred = self.decomposed_qa(sample)\n",
        "            elif method_name == 'tool_augmented':\n",
        "                pred = self.tool_augmented(sample)\n",
        "            elif method_name == 'self_consistency':\n",
        "                pred = self.self_consistency(sample)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown method: {method_name}\")\n",
        "\n",
        "            results.append(pred)\n",
        "\n",
        "        # Evaluate predictions\n",
        "        metrics = self.evaluate_predictions(gold_data, results)\n",
        "\n",
        "        print(f\"\\n\\n{Colors.BOLD}{method_name} evaluation completed in {time.time()-start_time:.1f}s{Colors.ENDC}\")\n",
        "        print(f\"{Colors.BOLD}Precision: {metrics['precision']:.3f}{Colors.ENDC}\")\n",
        "        print(f\"{Colors.BOLD}Recall: {metrics['recall']:.3f}{Colors.ENDC}\")\n",
        "        print(f\"{Colors.BOLD}F1: {metrics['f1']:.3f}{Colors.ENDC}\")\n",
        "        print(f\"True Positives: {metrics['true_pos']}\")\n",
        "        print(f\"False Positives: {metrics['false_pos']}\")\n",
        "        print(f\"False Negatives: {metrics['false_neg']}\")\n",
        "\n",
        "        # Display error details\n",
        "        error_details = metrics['error_details']\n",
        "        if error_details:\n",
        "            print(f\"\\n{Colors.UNDERLINE}Error Samples (showing first {min(max_errors, len(error_details))}):{Colors.ENDC}\")\n",
        "            for error in error_details[:max_errors]:\n",
        "                print(f\"\\n{Colors.BOLD}Sentence #{error['index']+1}{Colors.ENDC}\")\n",
        "                print(f\"True Positives: {error['tp']}, False Positives: {error['fp']}, False Negatives: {error['fn']}\")\n",
        "\n",
        "                # Visualize errors\n",
        "                visualization = self.visualize_errors(\n",
        "                    error['tokens'],\n",
        "                    error['gold_entities'],\n",
        "                    error['pred_entities']\n",
        "                )\n",
        "                print(\"Text with entities:\")\n",
        "                print(visualization)\n",
        "\n",
        "                # Print entity lists\n",
        "                print(\"\\nGold Entities:\")\n",
        "                for start, end, etype in error['gold_entities']:\n",
        "                    entity_text = \" \".join(error['tokens'][start:end+1])\n",
        "                    print(f\"- [{entity_text}:{etype}]\")\n",
        "\n",
        "                print(\"\\nPredicted Entities:\")\n",
        "                for start, end, etype in error['pred_entities']:\n",
        "                    entity_text = \" \".join(error['tokens'][start:end+1])\n",
        "                    print(f\"- [{entity_text}:{etype}]\")\n",
        "\n",
        "                print(\"\\n\" + \"-\"*50)\n",
        "        else:\n",
        "            print(f\"\\n{Colors.GREEN}No errors found!{Colors.ENDC}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12jQk10Ku7dP"
      },
      "source": [
        "#Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5yx41mQZ_EM"
      },
      "source": [
        "**Decompose QA**\n",
        "\n",
        "The paper's decomposed QA uses multi-turn dialogues processing one entity type per turn, with ChatGPT-determined label orders and accumulated context between turns. This sequential approach reduces ambiguity for nested entities but requires multiple API calls. Our implementation collapses this into a single-turn extraction where all entity types are identified simultaneously using a fixed label order and JSON output format. While faster with one API call, it lacks inter-label context and may struggle with complex entity interactions, though both methods share the core decomposition philosophy of isolating entity recognition tasks.\n",
        "I saw an increase in F1 score(~0.3) with the single turn method I implemented below, compared to the one that was used in the Paper. Additionaly the cost was reduced 3 times. From 5 requests per minutes to 15 request per minute per sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7g9V5b7yyUiC"
      },
      "outputs": [],
      "source": [
        "def decomposed_qa(self, sentence_data):\n",
        "    tokens, _ = self.prepare_conll_example(sentence_data)\n",
        "    text = \" \".join(tokens)\n",
        "\n",
        "    prompt = f\"\"\"Identify all entities in this text following CoNLL-2003 NER guidelines.\n",
        "Entity types: {', '.join(self.entity_types)}\n",
        "\n",
        "Text: \"{text}\"\n",
        "\n",
        "Instructions:\n",
        "- Extract ALL entity types in one pass\n",
        "- Return list of entities in format: [[\"entity text\", \"TYPE\"]]\n",
        "- Only return the JSON list, nothing else\n",
        "\n",
        "Entities:\"\"\"\n",
        "\n",
        "    response = self.generate(prompt)\n",
        "    if not response:\n",
        "        return []\n",
        "\n",
        "    entities = self._parse_response(response)\n",
        "    results = []\n",
        "    for entity_text, entity_type in entities:\n",
        "        if entity_type not in self.entity_types:\n",
        "            continue\n",
        "\n",
        "        entity_tokens = entity_text.split()\n",
        "        matches = self._find_token_spans(sentence_data['tokens'], entity_tokens)\n",
        "        for start, end in matches:\n",
        "            results.append((start, end, entity_type))\n",
        "\n",
        "    return results\n",
        "ConllNERProcessor.decomposed_qa = decomposed_qa\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zDjnEFva6_S"
      },
      "source": [
        "**Tool Augmented Comparison**\n",
        "\n",
        "The paper combines syntactic parsing with decomposed QA, using HanLP-generated features (POS/dependency/constituency trees) and explicit reasoning prompts. It employs noun phrases and domain-specific label orders for technical datasets. Our enhanced tool augmentation maintains single-turn execution while incorporating spaCy-generated POS/dependency tags and noun phrases, with a structured prompt directing syntactic analysis before extraction. Though both leverage external parsers, our approach consolidates syntax into one prompt section rather than per-label decomposition, trading some granularity for efficiency while adopting the paper's \"analyze then extract\" logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qOqj98xPd1f1"
      },
      "outputs": [],
      "source": [
        "def tool_augmented(self, sentence_data):\n",
        "        tokens, _ = self.prepare_conll_example(sentence_data)\n",
        "        text = \" \".join(tokens)\n",
        "\n",
        "        # Generate syntactic information\n",
        "        doc = nlp(text)\n",
        "        pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "        dep_tags = [(token.text, token.dep_) for token in doc]\n",
        "\n",
        "        prompt = f\"\"\"Perform CoNLL-2003 NER with syntactic information:\n",
        "\n",
        "Text: \"{text}\"\n",
        "POS tags: {pos_tags}\n",
        "Dependency tags: {dep_tags}\n",
        "Entity types: {self.entity_types}\n",
        "\n",
        "Instructions:\n",
        "1. Analyze syntactic structure first\n",
        "2. Identify entities based on text and syntax\n",
        "3. Return list in format: [[\"entity text\", \"TYPE\"]]\n",
        "4. Only return the JSON list, nothing else\n",
        "\n",
        "Entities:\"\"\"\n",
        "\n",
        "        response = self.generate(prompt)\n",
        "        if not response:\n",
        "            return []\n",
        "\n",
        "        entities = self._parse_response(response)\n",
        "        results = []\n",
        "        for entity_text, entity_type in entities:\n",
        "            if entity_type not in self.entity_types:\n",
        "                continue\n",
        "\n",
        "            tokens = entity_text.split()\n",
        "            if len(tokens) == 0:\n",
        "                continue\n",
        "\n",
        "            matches = self._find_token_spans(sentence_data['tokens'], tokens)\n",
        "            for start, end in matches:\n",
        "                results.append((start, end, entity_type))\n",
        "        return results\n",
        "\n",
        "ConllNERProcessor.tool_augmented = tool_augmented\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A_yBSsHt2lW_"
      },
      "outputs": [],
      "source": [
        "# Helper method for entity processing\n",
        "def _process_entities(self, response, original_tokens):\n",
        "    entities = self._parse_response(response)\n",
        "    results = []\n",
        "    for entity_text, entity_type in entities:\n",
        "        if entity_type not in self.entity_types:\n",
        "            continue\n",
        "\n",
        "        entity_tokens = entity_text.split()\n",
        "        matches = self._find_token_spans(original_tokens, entity_tokens)\n",
        "        for start, end in matches:\n",
        "            results.append((start, end, entity_type))\n",
        "    return results\n",
        "ConllNERProcessor._process_entities = _process_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrDjdZIGbHl9"
      },
      "source": [
        "**Self-Consistency Comparison**\n",
        "\n",
        "The paper implements two-stage voting at question-level (per entity type) or sample-level (full dialogue), using 5-7 samples with adaptive backoff and special nested entity handling. Our modified self-consistency preserves single-turn execution but adopts strict two-stage voting: mentions must exceed 50% agreement across 5 samples before type voting, with mention normalization to avoid duplicates. While lacking the paper's per-label voting, we mirror its >50% thresholds and duplicate prevention, focusing vote aggregation at the sample level rather than decomposed question-level for faster execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kOmq9-H5a_hM"
      },
      "outputs": [],
      "source": [
        "def self_consistency(self, sentence_data, num_samples=3):\n",
        "        \"\"\"Self-Consistency with two-stage voting for CoNLL data\"\"\"\n",
        "        tokens, _ = self.prepare_conll_example(sentence_data)\n",
        "        text = \" \".join(tokens)\n",
        "        prompt = f\"\"\"Perform CoNLL-2003 NER with these entity types: {self.entity_types}\n",
        "\n",
        "Text: \"{text}\"\n",
        "\n",
        "Instructions:\n",
        "- Extract entities matching the types\n",
        "- Return list in format: [[\"entity text\", \"TYPE\"]]\n",
        "- Only return the JSON list, nothing else\n",
        "\n",
        "Entities:\"\"\"\n",
        "\n",
        "        # Stage 1: Generate multiple responses\n",
        "        responses = []\n",
        "        for _ in range(num_samples):\n",
        "            response = self.generate(prompt, temperature=0.7)\n",
        "            if response:\n",
        "                entities = self._parse_response(response)\n",
        "                responses.append(entities)\n",
        "\n",
        "        if not responses:\n",
        "            return []\n",
        "\n",
        "        # Stage 2: Two-stage majority voting\n",
        "        # First stage: Vote for mentions\n",
        "        mention_votes = defaultdict(int)\n",
        "        mention_type_map = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        for response in responses:\n",
        "            for entity_text, entity_type in response:\n",
        "                mention_votes[entity_text] += 1\n",
        "                mention_type_map[entity_text][entity_type] += 1\n",
        "\n",
        "        # Keep mentions that appear in >50% of responses\n",
        "        threshold = num_samples / 2\n",
        "        selected_mentions = [m for m, cnt in mention_votes.items() if cnt > threshold]\n",
        "\n",
        "        # Second stage: Vote for types\n",
        "        results = []\n",
        "        for mention in selected_mentions:\n",
        "            if mention not in mention_type_map:\n",
        "                continue\n",
        "\n",
        "            # Get most voted type for this mention\n",
        "            selected_type = max(mention_type_map[mention].items(), key=lambda x: x[1])[0]\n",
        "            if selected_type not in self.entity_types:\n",
        "                continue\n",
        "\n",
        "            # Convert to token spans\n",
        "            tokens = mention.split()\n",
        "            matches = self._find_token_spans(sentence_data['tokens'], tokens)\n",
        "            for start, end in matches:\n",
        "                results.append((start, end, selected_type))\n",
        "\n",
        "        return results\n",
        "\n",
        "ConllNERProcessor.self_consistency = self_consistency\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt7hOfPzZr_P"
      },
      "source": [
        "#Evaluation\n",
        "\n",
        "Color-Coding Legend\n",
        "\n",
        "Green - Correct Prediction (True Positive)\t      [U.N.:ORG] (Correctly tagged as ORG)\n",
        "\n",
        "Red – Gold entity not predicted\t           [Paris:LOC] (Gold says LOC, but model missed it)\n",
        "\n",
        "Blue - Incorrect Prediction (False Positive) – Model predicted a wrong tag\t                       [official:PER] (Gold says O, model predicted PER)\n",
        "\n",
        "Default - Non-entity tokens (O tags)\t   meets (Correctly ignored)\n",
        "\n",
        "\n",
        "Important: With gemini 1.5 flash it will take arround 15 minutes to complete for 50 sentences. For more than 50 sentences it will hit the daily rate limit for the free tier API(which was used here for developing the methods and testing).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsCr_WldfZQ2"
      },
      "source": [
        "#Testing phase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "UdOmU098ZvNY",
        "outputId": "83608e0d-d25b-4ff5-a18a-24ca78968311"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span style=\"color:blue; font-weight:bold\">Loading dataset...</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<span style=\"color:green; font-weight:bold\">\n",
              "=== Evaluating Methods ===</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<span style=\"color:blue; font-weight:normal\">Using 4 samples from validation set</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<span style=\"color:darkblue; font-weight:bold\">\n",
              "▶ Evaluating Decomposed-QA...</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 3/4...\u001b[91mRate limited (429). Waiting 60s...\u001b[0m\n",
            "\u001b[91mRate limited (429). Waiting 320s...\u001b[0m\n",
            "\u001b[91mRate limited (429). Waiting 320s...\u001b[0m\n",
            "\u001b[91mRate limited (429). Waiting 320s...\u001b[0m\n",
            "Processing 4/4...\u001b[91mRate limited (429). Waiting 60s...\u001b[0m\n",
            "\u001b[91mRate limited (429). Waiting 320s...\u001b[0m\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-598624599>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, temperature, max_retries)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=yout_api_key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1678921160>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# 1. Decomposed-QA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdisplay_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n▶ Evaluating Decomposed-QA...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'darkblue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdecomposed_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mner_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'decomposed_qa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     results.append({\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m'Method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Decomposed-QA'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-598624599>\u001b[0m in \u001b[0;36mevaluate_method\u001b[0;34m(self, method_name, dataset, sample_size, max_errors)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'decomposed_qa'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposed_qa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tool_augmented'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_augmented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-1836365948>\u001b[0m in \u001b[0;36mdecomposed_qa\u001b[0;34m(self, sentence_data)\u001b[0m\n\u001b[1;32m     15\u001b[0m Entities:\"\"\"\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-598624599>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompt, temperature, max_retries)\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mbackoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_backoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackoff_factor\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{Colors.RED}Rate limited (429). Waiting {backoff}s...{Colors.ENDC}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{Colors.RED}HTTP Error: {e}{Colors.ENDC}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from IPython.display import display, HTML\n",
        "    import pandas as pd\n",
        "\n",
        "    # Display setup for Jupyter\n",
        "    def display_style(text, color='black', weight='normal'):\n",
        "        display(HTML(f'<span style=\"color:{color}; font-weight:{weight}\">{text}</span>'))\n",
        "\n",
        "    # Load dataset\n",
        "    display_style(\"Loading dataset...\", color='blue', weight='bold')\n",
        "    train_data, val_data, test_data = dev_data, dev_data, dev_data\n",
        "\n",
        "    # Initialize processor with your API key for Gemini 1.5 flash\n",
        "    ner_processor = ConllNERProcessor(api_key='your_api_key')\n",
        "\n",
        "\n",
        "\n",
        "    #******************This was used for prompt tuning the mehtods*****************\n",
        "    eval_subset = dev_data[1:5]# Start with 10 samples\n",
        "\n",
        "    #******************This was used for evaluation******************\n",
        "    #eval_subset = test_data[141:191]  # testing with 50 samples\n",
        "\n",
        "    display_style(\"\\n=== Evaluating Methods ===\", color='green', weight='bold')\n",
        "    display_style(f\"Using {len(eval_subset)} samples from validation set\", color='blue')\n",
        "\n",
        "    # Results storage\n",
        "    results = []\n",
        "\n",
        "    # 1. Decomposed-QA\n",
        "    display_style(\"\\n▶ Evaluating Decomposed-QA...\", color='darkblue', weight='bold')\n",
        "    decomposed_metrics = ner_processor.evaluate_method('decomposed_qa', eval_subset, max_errors=3)\n",
        "    results.append({\n",
        "        'Method': 'Decomposed-QA',\n",
        "        'Precision': decomposed_metrics['precision'],\n",
        "        'Recall': decomposed_metrics['recall'],\n",
        "        'F1': decomposed_metrics['f1'],\n",
        "        'TP': decomposed_metrics['true_pos'],\n",
        "        'FP': decomposed_metrics['false_pos'],\n",
        "        'FN': decomposed_metrics['false_neg']\n",
        "    })\n",
        "\n",
        "    # 2. Tool Augmentation\n",
        "    display_style(\"\\n▶ Evaluating Tool Augmentation...\", color='darkblue', weight='bold')\n",
        "    tool_metrics = ner_processor.evaluate_method('tool_augmented', eval_subset, max_errors=3)\n",
        "    results.append({\n",
        "        'Method': 'Tool Augmented',\n",
        "        'Precision': tool_metrics['precision'],\n",
        "        'Recall': tool_metrics['recall'],\n",
        "        'F1': tool_metrics['f1'],\n",
        "        'TP': tool_metrics['true_pos'],\n",
        "        'FP': tool_metrics['false_pos'],\n",
        "        'FN': tool_metrics['false_neg']\n",
        "    })\n",
        "\n",
        "    # 3. Self-Consistency\n",
        "    display_style(\"\\n▶ Evaluating Self-Consistency...\", color='darkblue', weight='bold')\n",
        "    sc_metrics = ner_processor.evaluate_method('self_consistency', eval_subset, max_errors=3)\n",
        "    results.append({\n",
        "        'Method': 'Self-Consistency',\n",
        "        'Precision': sc_metrics['precision'],\n",
        "        'Recall': sc_metrics['recall'],\n",
        "        'F1': sc_metrics['f1'],\n",
        "        'TP': sc_metrics['true_pos'],\n",
        "        'FP': sc_metrics['false_pos'],\n",
        "        'FN': sc_metrics['false_neg']\n",
        "    })\n",
        "\n",
        "    # Create and display summary table\n",
        "    df = pd.DataFrame(results)\n",
        "    df.set_index('Method', inplace=True)\n",
        "\n",
        "    display_style(\"\\n=== Summary Results ===\", color='green', weight='bold')\n",
        "\n",
        "    # Main metrics table\n",
        "    styled_df1 = (df[['Precision', 'Recall', 'F1']]\n",
        "                 .style\n",
        "                 .format(\"{:.3f}\")\n",
        "                 .background_gradient(cmap='Blues')\n",
        "                 .set_properties(**{'text-align': 'center'}))\n",
        "\n",
        "    # Set table styles\n",
        "    styled_df1.set_table_styles([{\n",
        "        'selector': 'th',\n",
        "        'props': [('text-align', 'center')]\n",
        "    }])\n",
        "\n",
        "    display(styled_df1)\n",
        "\n",
        "    # Detailed counts table\n",
        "    display_style(\"\\n=== Detailed Counts ===\", color='green', weight='bold')\n",
        "    styled_df2 = (df[['TP', 'FP', 'FN']]\n",
        "                 .style\n",
        "                 .format(\"{:.0f}\")\n",
        "                 .background_gradient(cmap='Reds')\n",
        "                 .set_properties(**{'text-align': 'center'}))\n",
        "\n",
        "    # Set table styles\n",
        "    styled_df2.set_table_styles([{\n",
        "        'selector': 'th',\n",
        "        'props': [('text-align', 'center')]\n",
        "    }])\n",
        "\n",
        "    display(styled_df2)\n",
        "\n",
        "    # Final recommendations\n",
        "    display_style(\"\\n=== Recommendations ===\", color='green', weight='bold')\n",
        "    best_method = df['F1'].idxmax()\n",
        "    display_style(f\"Best performing method: {best_method} (F1: {df.loc[best_method]['F1']:.3f})\",\n",
        "                 color='darkgreen', weight='bold')\n",
        "\n",
        "    if df['FP'].sum() > df['FN'].sum():\n",
        "        display_style(\"Model tends to make more False Positives (over-prediction)\", color='darkorange')\n",
        "    else:\n",
        "        display_style(\"Model tends to make more False Negatives (under-prediction)\", color='darkorange')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
